{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/patrik-\n",
      "[nltk_data]     sh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/patrik-sh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/patrik-\n",
      "[nltk_data]     sh/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/patrik-\n",
      "[nltk_data]     sh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/patrik-sh/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'text downloaded'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "alice_txt = open('alice.txt', encoding='utf8').read()\n",
    "\n",
    "'text downloaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             alice\n",
       "3         adventure\n",
       "5        wonderland\n",
       "7             lewis\n",
       "8           carroll\n",
       "            ...    \n",
       "34622    child-life\n",
       "34626         happy\n",
       "34627        summer\n",
       "34628           day\n",
       "34631           end\n",
       "Length: 12461, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text preprocessing\n",
    "\n",
    "#remove all new lines, lowercase\n",
    "alice_txt = alice_txt.replace(r'\\n', ' ')\n",
    "alice_txt = alice_txt.lower()\n",
    "\n",
    "#delete the useless beginning and the ending \n",
    "#BEGINNING = '[Illustration]'\n",
    "#ENDING = 'THE END'\n",
    "#print(len(alice_txt.split(BEGINNING)))\n",
    "#alice_txt = alice_txt.split(BEGINNING)[1]\n",
    "\n",
    "alice_tokenized = pd.Series(word_tokenize(alice_txt))\n",
    "\n",
    "alice_no_stopwords = alice_tokenized.loc[~alice_tokenized.isin(stopwords.words('english'))]\n",
    "\n",
    "alice_no_punction = alice_no_stopwords.loc[~alice_no_stopwords.isin(list(string.punctuation + string.digits + \"'\" + '\"' + '”' + '“' + '’' + '‘'))]\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "alice_preprocessed = alice_no_punction.apply(lambda word: lemmatizer.lemmatize(word))\n",
    "\n",
    "alice_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 1----\n",
      "       word  count\n",
      "225  little     15\n",
      "93     like     11\n",
      "50      way     11\n",
      "84      see     10\n",
      "48    think      9\n",
      "296    door      9\n",
      "126     one      8\n",
      "61     time      8\n",
      "22    could      8\n",
      "159    said      8\n",
      "Proposition for the name: Little Door Through Time\n"
     ]
    }
   ],
   "source": [
    "#divide by chapters creating an dataframe structure [chapter,word]\n",
    "\n",
    "chapterized_alice_arr = []\n",
    "\n",
    "chapter_nmb = 0\n",
    "for word in alice_preprocessed.iteritems():\n",
    "  if (word[1] == 'chapter'):\n",
    "    if chapter_nmb == 12:\n",
    "      chapter_nmb = 1\n",
    "    else:\n",
    "      chapter_nmb += 1\n",
    "  chapterized_alice_arr.append({ 'chapter': chapter_nmb, 'word': word[1] })\n",
    "\n",
    "chapterized_alice = pd.DataFrame(chapterized_alice_arr)\n",
    "\n",
    "def get_10_frequent_words(df: pd.DataFrame, chapter: int):\n",
    "  df_working = df[df.chapter == chapter]\n",
    "  unique_words = df_working[df_working.word != 'alice'].word.unique()\n",
    "\n",
    "  words_count = []\n",
    "\n",
    "  for w in unique_words:\n",
    "    words_count.append({\n",
    "      'word': w,\n",
    "      'count': df_working.loc[df_working.word == w].word.count()\n",
    "    })\n",
    "  \n",
    "  counted = pd.DataFrame(words_count)\n",
    "  return counted.sort_values(by=['count'], ascending=False).head(10)\n",
    "\n",
    "print('----for chapter 1----')\n",
    "print(get_10_frequent_words(chapterized_alice, 1))\n",
    "\n",
    "print('Proposition for the name: Little Door Through Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 2----\n",
      "       word  count\n",
      "29   little     16\n",
      "366   mouse     16\n",
      "107    said     12\n",
      "34     dear     11\n",
      "52       go     11\n",
      "171   thing     10\n",
      "20     foot     10\n",
      "15     like      9\n",
      "2      pool      9\n",
      "27       oh      9\n",
      "Proposition for the name: Little Mouse\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 2----')\n",
    "print(get_10_frequent_words(chapterized_alice, 2))\n",
    "\n",
    "print('Proposition for the name: Little Mouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 3----\n",
      "      word  count\n",
      "55    said     34\n",
      "56   mouse     21\n",
      "169   dodo     12\n",
      "45    know     11\n",
      "201    one      8\n",
      "3     long      7\n",
      "65    soon      7\n",
      "10    bird      6\n",
      "37    lory      6\n",
      "25     dry      6\n",
      "Proposition for the name: Little Mouse\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 3----')\n",
    "print(get_10_frequent_words(chapterized_alice, 3))\n",
    "\n",
    "print('Proposition for the name: Little Mouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 4----\n",
      "        word  count\n",
      "4     little     24\n",
      "2     rabbit     16\n",
      "77      said     14\n",
      "198      one     14\n",
      "5       bill     13\n",
      "23       get      9\n",
      "15     heard      9\n",
      "25      sure      9\n",
      "224  thought      9\n",
      "168    quite      8\n",
      "Proposition for the name: Little Rabbits Thought\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 4----')\n",
    "print(get_10_frequent_words(chapterized_alice, 4))\n",
    "\n",
    "print('Proposition for the name: Little Rabbits Thought')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 5----\n",
      "            word  count\n",
      "16          said     52\n",
      "3    caterpillar     27\n",
      "382       pigeon     12\n",
      "367      serpent     12\n",
      "55          well     10\n",
      "64        little     10\n",
      "119       minute      8\n",
      "32         think      7\n",
      "52          size      7\n",
      "155        youth      6\n",
      "Proposition for the name: Caterpillar, Pigeon and the Serpent\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 5----')\n",
    "print(get_10_frequent_words(chapterized_alice, 5))\n",
    "\n",
    "print('Proposition for the name: Caterpillar, Pigeon and the Serpent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 6----\n",
      "        word  count\n",
      "96      said     47\n",
      "225      cat     24\n",
      "34      like     16\n",
      "45    little     14\n",
      "60   duchess     14\n",
      "12   footman     12\n",
      "77      much     12\n",
      "209     baby     11\n",
      "21     would     11\n",
      "2        pig     10\n",
      "Proposition for the name: Caterpillar, Pigeon and the Serpent\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 6----')\n",
    "print(get_10_frequent_words(chapterized_alice, 6))\n",
    "\n",
    "print('Proposition for the name: Caterpillar, Pigeon and the Serpent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 9----\n",
      "        word  count\n",
      "11      said     57\n",
      "2       mock     27\n",
      "3     turtle     27\n",
      "312  gryphon     20\n",
      "12   duchess     19\n",
      "237    queen     14\n",
      "42      went     13\n",
      "190    never     11\n",
      "64    little     10\n",
      "140      say      9\n",
      "Proposition for the name: Little Turtle, who Mocked the Duchess\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 9----')\n",
    "print(get_10_frequent_words(chapterized_alice, 9))\n",
    "\n",
    "print('Proposition for the name: Little Turtle, who Mocked the Duchess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 10----\n",
      "          word  count\n",
      "24        said     45\n",
      "25     gryphon     31\n",
      "5       turtle     30\n",
      "4         mock     28\n",
      "118      would     15\n",
      "2      lobster     14\n",
      "57       dance     13\n",
      "431       soup     11\n",
      "430  beautiful     11\n",
      "21       voice     10\n",
      "Proposition for the name: Gryphon`s and Turtle`s Beautiful Dance\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 10----')\n",
    "print(get_10_frequent_words(chapterized_alice, 10))\n",
    "\n",
    "print('Proposition for the name: Gryphon`s and Turtle`s Beautiful Dance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 11----\n",
      "         word  count\n",
      "74       said     38\n",
      "4        king     26\n",
      "190    hatter     20\n",
      "37      court     15\n",
      "209  dormouse     13\n",
      "32        one     11\n",
      "5       queen      9\n",
      "188   witness      8\n",
      "53    thought      8\n",
      "30     rabbit      8\n",
      "Proposition for the name: The Hatter who Witnessed what the King Said\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 11----')\n",
    "print(get_10_frequent_words(chapterized_alice, 11))\n",
    "\n",
    "print('Proposition for the name: The Hatter who Witnessed what the King Said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----for chapter 12----\n",
      "       word  count\n",
      "56     said     50\n",
      "57     king     22\n",
      "52    would     12\n",
      "172   queen     10\n",
      "72   little     10\n",
      "89     jury      9\n",
      "87      one      8\n",
      "121  rabbit      8\n",
      "120   white      8\n",
      "20     head      8\n",
      "Proposition for the name: What the Jury Said\n"
     ]
    }
   ],
   "source": [
    "print('----for chapter 12----')\n",
    "print(get_10_frequent_words(chapterized_alice, 12))\n",
    "\n",
    "print('Proposition for the name: What the Jury Said')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 66),\n",
       " ('go', 54),\n",
       " ('get', 44),\n",
       " ('think', 33),\n",
       " ('begin', 20),\n",
       " ('come', 16),\n",
       " ('find', 16),\n",
       " ('look', 15),\n",
       " ('see', 15),\n",
       " ('try', 14)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_txt_no_strange_signs = alice_txt.replace('”', '').replace('“','').replace('’', '').replace('‘', '')\n",
    "\n",
    "sentences = [word_tokenize(sent) for sent in alice_txt_no_strange_signs.split('.')]\n",
    "sentences_alice = list(filter(lambda sent: 'alice' in sent, sentences))\n",
    "\n",
    "verbs = []\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "for sent in sentences_alice:\n",
    "  sent_preprocessed = list(filter(lambda w: w not in stopwords.words('english') ,sent))\n",
    "  sent_preprocessed = [lemmatizer.lemmatize(word, pos='v') for word in sent_preprocessed]\n",
    "  sentence_tagged = nltk.pos_tag(sent_preprocessed)\n",
    "  verbs_sent = list(filter(lambda w: w[1] == 'VB', sentence_tagged))\n",
    "  for v in verbs_sent:\n",
    "    verbs.append(v[0])\n",
    "\n",
    "verbs_counted = []\n",
    "\n",
    "for v in set(verbs):\n",
    "  verbs_counted.append((v, len(list(filter(lambda k: k==v,verbs)))))\n",
    "\n",
    "sorted(verbs_counted, key=lambda v: -v[1])[:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5c9fbd331fea3c481f4404cc8af350459f007b4c4df3c5795a543f0770733c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
