{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAqC8xXmZ1Av"
      },
      "source": [
        "## Convolutional Neural Network \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z8CfGD5Z1Ay"
      },
      "source": [
        "In this notebook you will learn to distinguish dogs from cats!\n",
        "\n",
        "Data:\n",
        "https://drive.google.com/drive/folders/1nzVk4GOvKR6P87uPszUkKMPtaXV_wrZf?usp=sharing\n",
        "\n",
        "Fill all the necessary gaps in cells below and fit neural networks for solving the binary classification task.\n",
        "\n",
        "## Task 1:\n",
        "\n",
        "1. Build and fit CNN with 3 convolutional layers for binary classification\n",
        "2. Evaluate accuracy on test data\n",
        "3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n",
        "\n",
        "First, let's load all the necessary functions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyzNnZpdZ1A4"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "Kernel venv (Python 3.8.10) is not usable. Check the Jupyter output tab for more information. \n",
            "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS-6t0_XZ1BL"
      },
      "source": [
        "The images collected for training and testing the deep learning model must be prepared: split the entire set into a training, validation and test sample, observing the balancing of classes (with binary classification they should be approximately equal in all three samples).\n",
        "\n",
        "This has _already_ been done: in the Cats_and_Dogs directory there are three subdirectories: train, test and val - training, test and validation samples, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK6VqL9Abk9v",
        "outputId": "30f60f8b-68c0-4da1-cd6c-04e43f18ddfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# if you are using google colab for this task you can mount your GoogleDrive as follows: \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# After running this cell you should enter the authorization code from your Google account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejt0NSnVZ1BP"
      },
      "outputs": [],
      "source": [
        "# Initialize the folders with train, test and validation datasets (in \"/My Drive/...\" or from your local repository where you have downloaded data):\n",
        "\n",
        "train = '/content/drive/MyDrive/Cats_and_Dogs/train'\n",
        "val =   '/content/drive/MyDrive/Cats_and_Dogs/val'\n",
        "test =  '/content/drive/MyDrive/Cats_and_Dogs/test'\n",
        "\n",
        "# The shape of the RGB image\n",
        "img_width, img_height, channels = 150, 150, 3 # you can try different sizes\n",
        "\n",
        "# input shape\n",
        "input_shape = (img_width, img_height, channels)\n",
        "# position matters!\n",
        "# Number_of_channels can be at the first or the last position\n",
        "# in our case - \"channels last\"\n",
        "\n",
        "# minibatch size\n",
        "batch_size = 64\n",
        "# train set size\n",
        "nb_train_samples = len(f'{train}cats') + len(f'{train}dogs')\n",
        "# validation set size \n",
        "nb_validation_samples = len(f'{val}cats') + len(f'{val}dogs')\n",
        "# test set size\n",
        "nb_test_samples = len(f'{test}cats') + len(f'{test}dogs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYe-jLGbZ1Bh"
      },
      "source": [
        "## Prepare the data.\n",
        "\n",
        "You don’t have to manually change the shapes of 25000 images and convert them into the necessary format for keras (img_width, img_height, 3).\n",
        "\n",
        "We will use the built-in image preprocessing function _ImageGenerator()_.\n",
        "\n",
        "It performs scaling, resizes selected images and prepares batches (mini-samples) to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GthRQyZHZ1CI"
      },
      "source": [
        "Set the network architecture by sequentially adding layers to it:\n",
        "1. A convolutional layer with 16 neurons, filter size 3x3. Activation function - 'relu'\n",
        "2. MaxPooling layer with filter size 2x2.\n",
        "3. A convolutional layer with 32 neurons, filter size 3x3. Activation function - 'relu'\n",
        "4. MaxPooling layer with filter size 2x2.\n",
        "5. A convolutional layer with 64 neurons, filter size 3x3. Activation function - 'relu'\n",
        "6. MaxPooling layer with filter size 2x2.\n",
        "7. Operation model.add (Flatten ()), which makes a one-dimensional vector of the resulting feature maps.\n",
        "8. A fully connected layer with 64 neurons. Activation function - 'relu'\n",
        "9. Use model.add (Dropout (0.5)) which excludes the edge from the current layer in the computational graph with a 50% probability to avoid overfitting.\n",
        "10. A fully connected layer with 1 neuron. Activation function - 'sigmoid', because binary classification model.\n",
        "\n",
        "Add to the model all the missing layers, by analogy with the already specified.\n",
        "Keras documentation: https://keras.io/layers/about-keras-layers/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncx9lh6LZ1Bk",
        "outputId": "a72837f9-fcdd-4a66-e890-7e29e86f1ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 2490 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    val,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNik7qzRZ1CU"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# 1: +Convolutional\n",
        "# For example:\n",
        "model.add(Conv2D(16, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 2: +Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
        "\n",
        "# 3:\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 4:  +Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
        "\n",
        "# 5:  +Convolutional\n",
        "model.add(Conv2D(64, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 6:  +Pooling \n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=None))\n",
        "\n",
        "# 7:  +Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# 8:  +Dense\n",
        "model.add(Dense(64))\n",
        "\n",
        "# 9:  +Dropout\n",
        "model.add(Dropout(0.5))\n",
        "# 10: +Dense\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnniirpHGEaO"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7blPtA5OfZOT",
        "outputId": "296ba715-fd4b-4d04-eb29-5e71cad5267f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 35s 35s/step - loss: 0.6973 - accuracy: 0.5781 - val_loss: 3.6974 - val_accuracy: 0.4531\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 32s 32s/step - loss: 3.3051 - accuracy: 0.5000 - val_loss: 0.6827 - val_accuracy: 0.5781\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.8237 - accuracy: 0.4375 - val_loss: 2.2233 - val_accuracy: 0.5469\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 29s 29s/step - loss: 2.3976 - accuracy: 0.5000 - val_loss: 2.1097 - val_accuracy: 0.5469\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 30s 30s/step - loss: 1.8886 - accuracy: 0.5625 - val_loss: 1.3635 - val_accuracy: 0.5312\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 27s 27s/step - loss: 1.3337 - accuracy: 0.5469 - val_loss: 0.8119 - val_accuracy: 0.5156\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 25s 25s/step - loss: 0.8125 - accuracy: 0.5312 - val_loss: 0.7133 - val_accuracy: 0.4219\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.7214 - accuracy: 0.4688 - val_loss: 0.6755 - val_accuracy: 0.6094\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.6846 - accuracy: 0.6094 - val_loss: 0.6986 - val_accuracy: 0.4844\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.7085 - accuracy: 0.4688 - val_loss: 0.7089 - val_accuracy: 0.4531\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fedc85338d0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use generator for training the model (\"fit\" method analog)\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBMrJqBHZ1DT",
        "outputId": "7e1feedc-9787-4443-c60c-fc1d0441c7a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 43.75%\n"
          ]
        }
      ],
      "source": [
        "# NOTE: if the accuracy on test data after 15 epochs is less than 80% smth goes wrong\n",
        "\n",
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mle_LO6XMJ62"
      },
      "source": [
        "Plot the graphs: \n",
        "\n",
        "- Loss(Number of epochs)\n",
        "\n",
        "- Accuracy(Number of epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xMasOmNHc61",
        "outputId": "8a293492-6b0b-4bb6-8896-3a459fb44919"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 26s 26s/step - loss: 0.7038 - accuracy: 0.4844 - val_loss: 0.7243 - val_accuracy: 0.3750\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.6979 - accuracy: 0.5156 - val_loss: 0.7185 - val_accuracy: 0.3594\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.6779 - accuracy: 0.5625 - val_loss: 0.6896 - val_accuracy: 0.5156\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.7079 - accuracy: 0.4062 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.6809 - accuracy: 0.5469 - val_loss: 0.6903 - val_accuracy: 0.5312\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.6893 - accuracy: 0.5000 - val_loss: 0.6800 - val_accuracy: 0.6250\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.7000 - accuracy: 0.4844 - val_loss: 0.6873 - val_accuracy: 0.5625\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.6927 - accuracy: 0.5469 - val_loss: 0.6870 - val_accuracy: 0.5625\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.6904 - accuracy: 0.5156 - val_loss: 0.6866 - val_accuracy: 0.5938\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 20s 20s/step - loss: 0.6818 - accuracy: 0.5469 - val_loss: 0.6891 - val_accuracy: 0.5781\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.6919 - accuracy: 0.5312 - val_loss: 0.6937 - val_accuracy: 0.4531\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 16s 16s/step - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6803 - val_accuracy: 0.6094\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.6973 - accuracy: 0.4375 - val_loss: 0.6864 - val_accuracy: 0.5312\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 16s 16s/step - loss: 0.6884 - accuracy: 0.5625 - val_loss: 0.6814 - val_accuracy: 0.6094\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 17s 17s/step - loss: 0.6903 - accuracy: 0.5000 - val_loss: 0.6865 - val_accuracy: 0.5312\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 15s 15s/step - loss: 0.6801 - accuracy: 0.5469 - val_loss: 0.6884 - val_accuracy: 0.5312\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 16s 16s/step - loss: 0.7010 - accuracy: 0.4531 - val_loss: 0.6873 - val_accuracy: 0.5625\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.6847 - accuracy: 0.4844 - val_loss: 0.6875 - val_accuracy: 0.6562\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 15s 15s/step - loss: 0.6993 - accuracy: 0.5000 - val_loss: 0.6958 - val_accuracy: 0.4688\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 15s 15s/step - loss: 0.6893 - accuracy: 0.5312 - val_loss: 0.6858 - val_accuracy: 0.5312\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fedc8506910>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use the generator to train the model (analogue of the fit method)\n",
        "# 1 epoch of training on a CPU will take 4-6 minutes. The GPU is an ~order of magnitude faster.\n",
        "# THE FIRST EPOCH USUALLY TAKES MUCH LARGER TIME AS KERAS SHOULD BUILD THE COMPUTATIONAL GRAPH\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs= 20, # try different number of epochs: 10, 15, 20; check the loss and accuracy;\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InwJ15gAHhPG",
        "outputId": "5693e5f8-d1b2-4e4f-9b6d-c3e9a2af5e10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 51.56%\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QESIOnCPZ1Dz"
      },
      "source": [
        "Let's try to improve the quality of recognition, using the method of transfer lerning. \n",
        "\n",
        "We will use weights of deep neural networks already trained on large dataset such as  ImageNet, and provide fine tuning of several additional dense layers on new data relevant to the current classification task. The more new images will differ from those on which the network has been trained, the more layers will need to be “retrained” in order to get good classification accuracy. The intuition here is that the model has already learned how to highlight the necessary features on the images in the large dataset, it only needs to be “tweaked” for a specific task.\n",
        "\n",
        "## Task 2\n",
        "\n",
        "1. Build and fit Transfer Learning model using pre-trained VGG16-model weights from keras application.\n",
        "2. Do the same with **another avaliable pre-trained deep learning model** from keras application https://keras.io/api/applications/.\n",
        "2. Evaluate accuracy on test data for p.1 and p.2\n",
        "3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n",
        "4. Check the performance of your model with the custom image of cat or dog (so the model will tell which class this image belongs to). Develop the function for the inference of the best algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md_9fT-nZ1D2",
        "outputId": "2ef2d2e6-84b5-491b-fe67-8f5fca5d30b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# First, download the weights of the VGG16 network trained on the ImageNet dataset:\n",
        "\n",
        "vgg16_net = VGG16(weights='imagenet', \n",
        "                  include_top=False,      # we take only the \"convolution\" part, the last layers we add ourselves\n",
        "                  input_shape=(150, 150, 3))\n",
        "vgg16_net.trainable = False               # clearly prescribe that we do NOT overload the network.\n",
        "                                          # Weights VGG16 in the process of learning will remain unchanged!\n",
        "\n",
        "vgg16_net.summary()                       # pay attention to the number of trained and untrained parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_DTDXqWZ1EG"
      },
      "source": [
        "We construct our model of \"transfer learning\" by adding two fully connected layers to VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKYlhGqTZ1EJ",
        "outputId": "17785ce9-c41f-473d-d168-75dcd31080ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# add layers to VGG16:\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vgg16_net)\n",
        "\n",
        "# + flattening\n",
        "# + Dense fullyconnected layer with 256 neurons\n",
        "# + ReLu\n",
        "# + Dropout\n",
        "# + Dense layer with 1 neuron\n",
        "# + sigmoid\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKU1pQEeZ1Ea"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=1e-5), \n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "gNX7L-MIZ1FX",
        "outputId": "2ea6e77a-3555-4011-ab8f-edbe21278377"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5c0f953254fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     validation_steps=nb_validation_samples // batch_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# We also use the generator to train the model (similar to the fit method)\n",
        "# Without using a GPU, learning 1 epoch of such a network will take about an hour. Plan your time =)\n",
        "# If you have access to a GPU, you can try 10-12 epochs - the quality should increase even more.\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=5,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMCxq21YZ1Fh"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab5_from_lab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
